%*******************************************************
% Abstract
%*******************************************************
%\renewcommand{\abstractname}{Abstract}
\pdfbookmark[1]{Abstract}{Abstract}
\begingroup
\let\clearpage\relax
\let\cleardoublepage\relax
\let\cleardoublepage\relax

\chapter*{Abstract}


Conditional Value-at-Risk (CVaR) is a well-known measure of risk that has been used for decades in the financial sector and has been directly equated to robustness, an important component of Artificial Intelligence (AI) safety. In this thesis we focus on optimizing CVaR in the context of Reinforcement Learning, a branch of Machine Learning that has brought significant attention to AI due to it's generality and potential.

As a first original contribution, we extend the CVaR Value Iteration algorithm (\citet{chow2015risk}) by utilizing the distributional nature of the CVaR objective. The proposed extension reduces computational complexity of the original algorithm from polynomial to linear and we prove it is equivalent to the said algorithm for continuous distributions.

Secondly, based on the improved procedure, we propose a sampling version of CVaR Value Iteration we call CVaR Q-learning. We also derive a distributional policy improvement algorithm, prove it's validity, and later use it as a heuristic for extracting the optimal policy from the converged CVaR Q-learning algorithm.

Finally, to show the scalability of our method, we propose an approximate Q-learning algorithm by reformulating the CVaR Temporal Difference update rule as a loss function which we later use in a deep learning context.

All proposed methods are experimentally analyzed, using a risk-sensitive gridworld environment for CVaR Value Iteration and Q-learning and a challenging visual environment for the approximate CVaR Q-learning algorithm. All trained agents are able to learn risk-sensitive policies, including the  Deep CVaR Q-learning agent which learns how to avoid risk from raw pixels.



%\newpage
%
%\begin{otherlanguage}{czech}
%\pdfbookmark[1]{Abstrakt}{Abstrakt}
%\chapter*{Abstrakt}
%Conditional Value-at-Risk (CVaR) je známá míra rizika používaná ve finančním sektoru po dekády, a která byla přímo ***equated** s robustností, důležitou komponentou bezpečnosti v Umělé Inteligenci (UI). V této diplomové práci se soustředíme na optimalizaci CVaRu v kontextu posilovaného učení, větví strojového učení která *** díky své obecnosti a potenciálu.
%
%Naším prvním originálním příspěvkem je rozšíření algoritmu CVaR Value Iteration
%\end{otherlanguage}

\endgroup

\vfill
